# -------- [selfplay_duo.yaml] --------
behaviors:
  ### 1) Attacker ##############################################
  Attackagent:
    trainer_type: ppo
    hyperparameters:
      batch_size:        2048            #
      buffer_size:       20480           # 
      learning_rate:     3.0e-4
      beta:              5.0e-4
      epsilon:           0.2
      lambd:             0.95
      num_epoch:         3
      learning_rate_schedule: linear
    network_settings:
      normalize:         true
      hidden_units:      256
      num_layers:        3
      memory:
        sequence_length: 64
    reward_signals:
      extrinsic:
        gamma:           0.99
        strength:        1.0

    
    self_play:
      window:            8               # 
      save_steps:        50000           # 
      team_change:       20000           # 
      swap_steps:        5000            # 
      swap_prob:         0.5             #
      initial_elo:       1200
      play_against_latest_model_ratio: 0.2  
    
      include_self:      false         

    max_steps:           5e6             
    checkpoint_interval: 200000


  Defenderagent:
    trainer_type: ppo
    hyperparameters:
      batch_size:        2048
      buffer_size:       20480
      learning_rate:     3.0e-4
      beta:              5.0e-4
      epsilon:           0.2
      lambd:             0.95
      num_epoch:         3
      learning_rate_schedule: linear
    network_settings:
      normalize:         true
      hidden_units:      256
      num_layers:        3
    reward_signals:
      extrinsic:
        gamma:           0.99
        strength:        1.0

  
    self_play:
      window:            8
      save_steps:        50000
      team_change:       20000
      swap_steps:        5000
      swap_prob:         0.5
      initial_elo:       1200
      play_against_latest_model_ratio: 0.2
      include_self:      false

    max_steps:           5e6
    checkpoint_interval: 200000


